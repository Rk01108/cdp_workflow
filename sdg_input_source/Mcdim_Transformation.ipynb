{"cells": [{"cell_type": "code", "metadata": {"id": "95617052_0.5275645120813817"}, "execution_count": null, "source": ["import pandas as pd\nfrom datetime import datetime\nfrom clickhouse_driver import Client\nfrom faker import Faker\nimport random\nimport logging\n\nfake = Faker('en-us')\n\ncity_zip_mapping = {\n    \"New York\": \"10001\",\n    \"Los Angeles\": \"90001\",\n    \"Chicago\": \"60601\",\n    \"Houston\": \"77001\",\n    \"Phoenix\": \"85001\",\n    \"Philadelphia\": \"19101\",\n    \"San Antonio\": \"78201\",\n    \"San Diego\": \"92101\",\n    \"Dallas\": \"75201\",\n    \"San Jose\": \"95101\",\n    \"Austin\": \"73301\",\n    \"Jacksonville\": \"32099\",\n    \"San Francisco\": \"94101\",\n    \"Indianapolis\": \"46201\",\n    \"Columbus\": \"43085\",\n    \"Fort Worth\": \"76101\",\n    \"Charlotte\": \"28201\",\n    \"Seattle\": \"98101\",\n    \"Denver\": \"80201\",\n    \"Washington\": \"20001\",\n    \"Boston\": \"02101\",\n    \"El Paso\": \"79901\",\n    \"Nashville\": \"37201\",\n    \"Detroit\": \"48201\",\n    \"Oklahoma City\": \"73101\",\n    \"Portland\": \"97201\",\n    \"Las Vegas\": \"89101\",\n    \"Memphis\": \"38101\",\n    \"Louisville\": \"40201\",\n    \"Baltimore\": \"21201\",\n    \"Milwaukee\": \"53201\",\n    \"Albuquerque\": \"87101\",\n    \"Tucson\": \"85701\",\n    \"Fresno\": \"93701\",\n    \"Mesa\": \"85201\",\n    \"Sacramento\": \"94203\",\n    \"Atlanta\": \"30301\",\n    \"Kansas City\": \"64101\",\n    \"Colorado Springs\": \"80901\",\n    \"Raleigh\": \"27601\",\n    \"Omaha\": \"68101\",\n    \"Miami\": \"33101\",\n    \"Long Beach\": \"90801\",\n    \"Virginia Beach\": \"23450\",\n    \"Oakland\": \"94601\",\n    \"Minneapolis\": \"55401\",\n    \"Tampa\": \"33601\",\n    \"Arlington\": \"22201\",\n    \"New Orleans\": \"70112\",\n}\n\ndef read_clickhouse_to_dataframe(host,port,user,password,database):\n    query = 'SELECT email_address,first_name,last_name,address_1,address_2,gender,postal_code,city,primary_phone_nbr,runid,source_name,file_name FROM registria'\n    # Connect to ClickHouse server\n    client1 = Client(host=host, port=port, user=user, password=password, database=database)\n    try:\n        # Execute SQL query to fetch data\n        result = client1.execute(query)\n        columns = ['email_address', 'first_name', 'last_name', 'address_1', 'address_2', 'gender', 'postal_code', 'city', 'primary_phone_nbr', 'runid', 'source_name', 'file_name']\n        df = pd.DataFrame(result, columns=columns)\n        df=df.to_dict(orient=\"records\")\n\n    finally:\n        # Close ClickHouse connection\n        client1.disconnect()\n\n    return df\n\ndef generate_us_state_city_data():\n    us_state_city_data = []\n    state_name = fake.state()\n    city_name = random.choice(list(city_zip_mapping.keys()))  # Select a random city from the keys of the dictionary\n    zip_code = city_zip_mapping[city_name]  # Get the zip code for the selected city\n    address = fake.street_address()\n    city_data = {\"city\": city_name, \"zip_code\": zip_code, \"address\": address}\n    us_state_city_data.append({\"state\": state_name, \"city\": city_data})\n    return us_state_city_data\n\ndef func_data_mod(df1):\n    for val in df1:\n        try:\n            var1=generate_us_state_city_data()\n            val['first_name']=val['first_name'].split()[1]\n            val['last_name']=val['last_name'].split()[1]\n            val['email']=f\"{val['first_name']}{val['last_name']}@{fake.free_email_domain()}\"\n            val['postal_code']=var1[0]['city']['zip_code']\n            val['address_1']=fake.street_address()\n            val['address_2']=\"\"\n            val['address_3']=\"\"\n            val['city']=var1[0]['city']['city']\n            val['insertion_date']=str(datetime.now().date())\n        except Exception as e:\n            logging.info(e)\n    return df1\n\ndef main_new(df1,host,port,user,password,database):\n    lis=[]\n    dfs=func_data_mod(df1)\n    df = read_clickhouse_to_dataframe(host,port,user,password,database)\n    # df=df[60:100]\n    start_percentage = 60\n    end_percentage = 100\n    total_rows = len(df)\n    start_index = int(total_rows * (start_percentage / 100))\n    end_index = int(total_rows * (end_percentage / 100))\n    df = df[start_index:end_index]\n  \n    for i in range(len(df)):\n        try:\n            dfs[i]['runid']=df[i]['runid']\n            dfs[i]['postal_code']=df[i]['postal_code']\n            dfs[i]['phone']=df[i]['primary_phone_nbr']\n            dfs[i]['last_name']=df[i]['last_name']\n            dfs[i]['gender']=df[i]['gender']\n            dfs[i]['first_name']=df[i]['first_name']\n            dfs[i]['file_name']=df[i]['file_name']\n            dfs[i]['email']=df[i]['email_address']\n            dfs[i]['city']=df[i]['city']\n            dfs[i]['address_2']=df[i]['address_2']\n            dfs[i]['address_1']=df[i]['address_1']\n            dfs[i]['address_3']=\"\"\n            dfs[i]['source']=df[i]['source_name']\n            lis.append(dfs[i])\n        except Exception as e:\n            logging.info(e)\n    for j in range(len(df), len(dfs)):\n        try:\n            lis.append(dfs[j])\n        except Exception as e:\n            logging.info(e)\n    return lis"], "outputs": []}], "metadata": {}, "nbformat": 4, "nbformat_minor": 2}